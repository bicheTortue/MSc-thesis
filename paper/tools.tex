\section{Python tools}

\subsection{Weights generation}

The weigths were trained in python \cite{python} using the tensorflow library \cite{tensorflow}.

The weights need to be trained. The training is performed using the analog activation functions generated by the circuits in \cref{subsec:af}. The circuit is thus trained as if it were trained directly on the chip, circuit's inaccuracies aside.

The weights are constrained to make sure the voltage is within the active voltage range of the circuit. If the voltage gets out of range, the weights will not be correct as the voltage cannot get out of range in the physical circuit.

Once the weights are trained, they are saved in a file, that will later serve as the basis to generate the netlist.

The code used to generate the weights is available on my github repo \cite{lstmWei}.

\subsection{Netlist generation}

In order to be able to run the simulation with different kinds of \ac{NN} architecture of varying sizes. The point of the part is thus to explain how the netlist generator tool works.

The netlist is generated using a python script to generate a SPICE netlist. It can generate the netlist for different kinds of circuits. It can generate both LSTM and GRU circuits, with any size of input, time steps or even number of hidden states. When it is possible the serial size can also be selected.

The weights are stored in a single file. This file contains a brief description of the architecture being used. The first index stores this desciption. The following indexes are for the weights of each layer, in the order given in the description. The weights are stored in a python list and are distributed among the different resistances.

All the code used to generate the netlist can be found on my github page \cite{lstmGen}.
