\section{Future work}\label{sec:further}

\subsection{Changing the verilog-A files for real circuit implementation}

Making the system actually one hundred percent implemented for inference is the obvious next step in making a fully analog \ac{LSTM} computer.

This means designing both an \ac{opAmp} for the current flowing through the circuit and a voltage multiplier working in the right voltage range.

\subsection{Circuit controller}\label{subsec:control}

The final circuit will need an external controller to manage diffenrent things in the circuit. This wasn't created in this thesis but will have to be in order to have a functionning circuit once fabricated %TODO ref annex

The controller will increase the power consumption of the overall system. However, due to the slow (precision of about $1\mu s$) nature of the system requirements, the controller will be very low power, and won't affect the overall power consumption of the final system.

The controller will have several roles in the system :
\begin{itemize}
  \item The first role will be to manage the different flags. This means that the controller will have to set those to high or low in order to control the system. This includes flags like the enable flags of the voltage driven crossbar array (\cref{subsec:serpar}) and those for the memory cell control.
  \item Anoter use for this controller is to reset the memory cell to $V_{cm}$ ($0$ as real value equivalent, \cref{tab:valConv}). This will be done by enabling the input and then applying $V_{cm}$ to the input, this will set the capacitor to $V_{cm}$. This has to be done everytime the circuit is ran.
  \item The controller will also be used to control the memristors internal resistance and control the weights. Depending on the type of memristor, the method and time to change the internal resistance differs. That will only be use for inSitu trainning(\cref{subsec:inSitu}).
\end{itemize}

\subsection{inSitu trainning}\label{subsec:inSitu}

Of course the first thing that comes to mind to improve the system and making it actually usable for a real world application would be doing inSitu training. Training within the analog system would mean implementing the backpropagation algorithm. Here, two options are available :

\begin{itemize}
  \item The easiest option would be to use the external controller (\cref{subsec:control}) to make the backprogation computation needed. This is not the best option, as the backpropagation would be happening in digital. This digital computation would have to happen as fast as the analog computation and thus a much faster controller would be required, meaning a bigger power consumption.
  \item The ideal way of implementing the backpropagation would be using an analog system similar to the one that is used for the inference. This would still mean having a controller to change the internal resistance of the memristors, this version would require a slower clock and making the controller lower powered. Using an analog implementation might also harm the system, as the backpropagation algorithm will probably be simpler and reduce the efficiency of the system.
\end{itemize}

Figure out how to change the values of the weights for the inSitu training. Different from \cref{sec:wei2res}.

Training directly on the chip has a great advange over external training. Indeed training within the chip will allow to completely ignore the wires own resistance in the crossbar array. This is because they will an integral part of the weights, if the weight needs to be lowered then the resistance will be raised (because the conductances need to be lowered). %TODO finish with better explainnation

\subsubsection{Only change the value of one of the two memristor}%TODO

\subsection{Permanent training}

Once the training is fully implemented in an analog computer, the next step would be to find a way to permanently training the system. Meaning that any new information will be used to update the weights. This means that the system would need to know if the prediction it has made is correct or not.

\subsection{\ac{LSTM} continuous mode}

This would allow to have a real time results and not having to retake the same inputs several times. Basically it would be like %TODO Make graphs

This might be something that already exist that I didn't find anything about.

\subsection{Other \acp{LSTM} variants}

As discused before(\cref{sec:genwei}), they are only two of the \ac{LSTM} variants available in Keras. Nonetheless, it is possible to write custom layer function for Keras. Creating a layer from scratch is very time consuming and not so interresting for the scope the results needed. It can be done to extend the reach of the work.
