\section{Conclusion}\label{sec:conc}

\subsection{Performances}

\subsubsection{\ac{LSTM}}

The circuit's performance has been evaluated in the previous chapter. The results highly depend on the parameters at play. For example the complexity of the dataset used, out of the two used in the thesis, the airline dataset is the simple dataset while the \ac{C. elegans} dataset is the more complicated datset.

The best performance is the with the airline dataset, using the circuit with a serial size of one ($n_s=1$) (\cref{tab:airlineAnalog}). While the results are not quite right, it is assumed that this issue will be elevated once inSitu training is implemented (\cref{subsec:inSitu}).

More complex datsets like \ac{C. elegans}, the issue is getting more present. Indeed, the dataset feeds to the circuit four inputs across a thousand time steps and outputs just as much data. Any inaccuracy is scaled up.

With a simple input sequence, such as sequence 5 (\cref{graph:io5Celegans}), the resulting predictions are quite good and on par with what is expected. The predictions are a bit late and it is not clear what is causing this specific issue. A theory is that the memory cells deteriorate its stored value by a very small amount every time step, thus the stored value is affect a lot after a large amount of time steps.

More complex input sequences produce even more inaccuracies. Indeed, when working with sequence 15 (\cref{graph:io15Celegans}), the inaccuracies spiral up and gives out a barely usable prediction. The curve generated does not fit its digital counterpart anymore.

The results obtained demonstrate that the \ac{LSTM} circuit block can be run with low error when dealing with simple inputs. The circuit is assumed to be ready for a full simulation, meaning also training with the analog circuit.

\subsubsection{\ac{GRU}}

The \ac{GRU} circuit, while being present, is still a work in progress. The outputed predictions are scaled down for a still unknown reason, but show the right output shape. Once those issues are dealt with and have been fixed, the \ac{GRU} circuit will be ready for an analog training as well.

\subsection{Execution time}

The inference time is quite tricky to deal with. While the analog circuit's inference time is set, it gets more complicated when trying to get the digital inference time. The digital inference time depends on the computer it is being run on. The \acp{CPU} used in embedded sytems, the main application for this work, are usually not very fast as they are intended to be low powered. This parts will thus only dicuss of the inference of the analog circuit.

\subsubsection{Airline inference}

The airline problem feeding two inputs to the circuit to get a single output, it will have to be run $144$ times to get all the output data.
The inference time depends on the serial size being used :

\begin{itemize}
  \item $n_s=1$ : The output can be read as a voltage on the output net from $t_0=18\mu s$ to $t_1=22\mu s$.
  \item $n_s=2$ : The output can be read as a voltage on the output net from $t_0=34\mu s$ to $t_1=38\mu s$.
  \item $n_s=4$ : The output can be read as a voltage on the output net from $t_0=66\mu s$ to $t_1=70\mu s$.
\end{itemize}

Those are the times it takes to compute one of the outputs. It takes $144$ times longer to get all of the results.

\subsubsection{\ac{C. elegans} inference}

This sequence is a bit more complicated, for every input sequence with a thousand time steps, there are a thousand output vectors being read. Here, the inference time also depends on the serial size.

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    \rowcolor{gray}
    Serial size & $n_s=1$ & $n_s=2$ & $n_s=4$ & $n_s=8$\\
    \hline
    Start of first output & $9\mu s$ & $17\mu s$ & $33\mu s$ & $65\mu s$\\
    \hline
    End of first output & $13\mu s$ & $21\mu s$ & $37\mu s$ & $69\mu s$\\
    \hline
    Output period & $9\mu s$ & $17\mu s$ & $33\mu s$ & $65\mu s$\\
    \hline
    Start of last output & $9ms$ & $17ms$ & $33ms$ & $65ms$\\
    \hline
    End of last output & $9ms +4\mu s$ & $17ms+4\mu s$ & $33ms+4\mu s$ & $65ms+4\mu s$\\
    \hline
  \end{tabular}
  \caption{First and last read times for the different serial sizes}
  \label{tab:readTimesCelegans}
\end{table}

\Cref{tab:readTimesCelegans} shows the first and last output time range with the period. All of the output times can be determined using the first time range and using the period. A sequence consists of $500ms$ as explained in \cref{subsec:celegans}, the time steps are physically $500\mu s$ appart, in the case where the circuit would be used to do real time inference, the circuit would have to be slowed down to be on sync with the inputs. The circuit could could be used in a real time use for this time sensitive problem.

\subsection{onChip area}\label{subsec:area}

The \ac{LSTM} and \ac{GRU} blocks' onChip area are impossible to estimate, as parts of the circuits are made of verilog-A models. However, to get a general idea of the area of the chip, it can be assumed that the area of the circuit mainly depends on the the area of a memrisor, because the area of a memristor is much greater than the ones of the other components. Since the number of memristors is the number of weights in the circuit, the minimum area of any \ac{NN} can be determined. The area for a memristor was determined using the feature size of the memristors that can be fabricated at \ac{INESC}. The typical memristor that can be fabricated at \ac{INESC} is $3\mu m$, which would make the approximate area for a memristor $A_{memristor}=9\mu m^2=9\cdot 10^{-12} m^2$

\Cref{tab:areas} contains several \acp{NN} models with their number of parameters, a minimum onChip area and an estimated feature size. None of those values have any scientific ground, they are just here to give general idea of the kind of circuit thta could be fabricated. Those areas only considers the area of the memristors, using a two memristor per synapse architecture like the one used in the thesis.

The feature size represents the length of the side of the chip if the chip was manufactured in a square.

The values of \acp{LLM}, such as \ac{LLaMA}-2 \textbf{Meta}'s \ac{LLM} and the two last versions of \acp{GPT} the \ac{LLM} that powers \textit{ChatGPT}, were included to show how the area of the chip scales up. Those models do not use \acp{RNN}, and futhermore, give out ridiculous areas. Fabricating such cicuits in analog is not feasible witht the current technologies.

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    \rowcolor{gray}
    Model & Parameters & Minimum area & Approximate feature size \\
    \hline
    Airline \ac{GRU} $n_h=4$ & $77$ & $1386\mu m^2$ & $37.2\mu m$\\
    \hline
    Airline \ac{LSTM} $n_h=4$ & $101$ & $1818\mu m^2$ & $42.6\mu m$\\
    \hline
    \ac{C. elegans} \ac{GRU} $n_h=8$ & $348$ & $6264\mu m^2$ & $79.1\mu m$\\
    \hline
    \ac{C. elegans} \ac{LSTM} $n_h=8$ & $452$ & $8136\mu m^2$ & $90.2\mu m$\\
    \hline
    \multirow{3}{*}{\acs{LLaMA}-2} & $7\cdot 10^9$ & $1260 cm^2$ & $35.5 cm$ \\
    \cline{2-4}
    & $13\cdot 10^9$ & $2340 cm^2$ & $48.4 cm$ \\
    \cline{2-4}
    & $70\cdot 10^9$ & $1.26 m^2$ & $1.12 m$ \\
    \hline
    \acs{GPT}-3 & $175\cdot 10^9$ & $3.14 m^2$ & $1.77m$\\
    \hline
    \acs{GPT}-4 & $1\cdot 10^{12}$ & $18.0 m^2$ & $4.24m$\\
    \hline
  \end{tabular}
  \caption{Estimated onChip area for different models of \acp{NN}}
  \label{tab:areas}
\end{table}

Nevertheless, it is interresting to look at those approximation. It shows that the simple models used in this work would take a very small onChip area, even though this a very raw number. It also shows the current limit with state of the art \acp{NN} at the current time.

The onChip area of small \acp{NN} such as the ones used in this work are very reasonable and could easily be fabricated for embedded use.
