\section{Conclusion}\label{sec:conc}

\subsection{Performances}

\subsubsection{\ac{LSTM}}

The circuit's performance has been evaluated in the previous chapter. The results highly depend on the parameters at play. For example the complexity of the dataset used, out of the two used in the thesis, the airline dataset is the simple dataset while the \ac{C. elegans} dataset is the more complicated datset.

The best performance is the with the airline dataset, using the circuit with a serial size of one ($n_s=1$) (\cref{tab:airlineAnalog}). While the results are not quite right, it is assumed that this issue will be elevated once inSitu training is implemented (\cref{subsec:inSitu}).

More complex datsets like \ac{C. elegans}, the issue is getting more present. Indeed, the dataset feeds to the circuit four inputs across a thousand time steps and outputs just as much data. Any inaccuracy is scaled up.

With a simple input sequence, such as sequence 5 (\cref{graph:io5Celegans}), the resulting predictions are quite good and on par with what is expected. The predictions are a bit late and it is not clear what is causing this specific issue. A theory is that the memory cells deteriorate its stored value by a very small amount every time step, thus the stored value is affect a lot after a large amount of time steps.

More complex input sequences produce even more inaccuracies. Indeed, when working with sequence 15 (\cref{graph:io15Celegans}), the inaccuracies spiral up and gives out a barely usable prediction. The curve generated doesn't fit its digital counterpart anymore.

The results obtained demonstrate that the \ac{LSTM} circuit block can be run with low error when dealing with simple inputs. The circuit is assumed to be ready for a full simulation, meaning also training with the analog circuit.

\subsubsection{\ac{GRU}}

The \ac{GRU} circuit, while being present, is still a work in progress. The outputed predictions are scaled down for a still unknown reason, but show the right output shape. Once those issues are dealt with and have been fixed, the \ac{GRU} circuit will be ready for an analog training as well.

\subsection{onChip area}\label{subsec:area}

The \ac{LSTM} and \ac{GRU} blocks's onChip area is impossible to estimate, as part of the circuit is made of verilog-A models. However, to get a general idea of the area of the chip, it can be assumed that the area of the circuit mainly depends on the the area of a memrisor, because the area of a memristor is much greater than the ones of the other components. Since the number of memristors is the number of weights in the circuit, the minimum area of any \ac{NN} can be determined. The area for a memristor was determined using the feature size of the memristors that can be fabricated at \ac{INESC}. The typical memristor that can be fabricated at \ac{INESC} is $3\mu m$, which would make the approximate area for a memristor $A_{memristor}=9\mu m^2=9\cdot 10^{-12} m^2$

\Cref{tab:areas} contains several \acp{NN} models with their number of parameters, a minimum onChip area and an estimated feature size. None of those values have any scientific ground, they are just here to give general idea of the kind of circuit thta could be fabricated. Those areas only considers the area of the memristors, using a two memristor per synapse architecture like the one used in the thesis.

The feature size represents the length of the side of the chip if the chip was manufactured in a square.

The values of \acp{LLM} were included to show how the area of the chip scales up. Those models don't use \acp{RNN}, and futhermore, give out ridiculous areas. Fabricating such cicuits in analog is not feasible witht the current technologies.

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    \rowcolor{gray}
    Model & Parameters & Minimum area & Approximate feature size \\
    \hline
    Airline \ac{GRU} $n_h=4$ & $77$ & $1386\mu m^2$ & $37.2\mu m$\\
    \hline
    Airline \ac{LSTM} $n_h=4$ & $101$ & $1818\mu m^2$ & $42.6\mu m$\\
    \hline
    \ac{C. elegans} \ac{GRU} $n_h=8$ & $348$ & $6264\mu m^2$ & $79.1\mu m$\\
    \hline
    \ac{C. elegans} \ac{LSTM} $n_h=8$ & $452$ & $8136\mu m^2$ & $90.2\mu m$\\
    \hline
    \multirow{3}{*}{\acs{LLaMA}-2} & $7\cdot 10^9$ & $1260 cm^2$ & $35.5 cm$ \\
    \cline{2-4}
    & $13\cdot 10^9$ & $2340 cm^2$ & $48.4 cm$ \\
    \cline{2-4}
    & $70\cdot 10^9$ & $1.26 m^2$ & $1.12 m$ \\
    \hline
    \acs{GPT}-3 & $175\cdot 10^9$ & $3.14 m^2$ & $1.77m$\\
    \hline
    \acs{GPT}-4 & $1\cdot 10^{12}$ & $18.0 m^2$ & $4.24m$\\
    \hline
  \end{tabular}
  \caption{Estimated onChip area for different models of \acp{NN}}
  \label{tab:areas}
\end{table}

Nevertheless, it is interresting to look at those approximation. It shows that the simple models used in this work would take a very small onChip area, even though this a very raw number. It also shows the current limit with state of the art \acp{NN} at the current time.
