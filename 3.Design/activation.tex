\section{The activation functions}
\label{sec:af}

Activation functions play a great role in the results obtained \cite{af}. It is the reason why making good Activation function circuits is fundamental. Of course the easy way would be to simply design a hard sigmoid ($h(x)=max(0,min(1,\frac{x+1}{2}))$), the issue being that the hard sigmoid is much worse than the regular sigmoid, especially for regression problems \cite{hardSigm}. The same goes for the \ac{tanh} and hard \ac{tanh} functions.

Designing an analog activation function as close to the original is very important for the final result's quality.


\subsection{The circuit}

The circuit used is the same as the one in \cite{thesisRef}, the circuit is the one shown in figure \ref{fig:afCircuit}. The technology used being different, all the parameters had to be determined empirically to best fit a sigmoid shape. The parameters can be found in ( TODO : show af parameters ).

Due to the nature of the functions we want to generate, we will use the same circuit for both a sigmoid and a \ac{tanh} like functions. The two different functions are generated by changing two parameters.

The functions generated are the same and only differ by their output range.

\begin{figure}[H]
  \centering
  \includesvg[width=\textwidth]{activation/circuit}
  \caption{Activation functions circuit}
  \label{fig:afCircuit}
\end{figure}

\subsection{The results}

This circuit outputs a voltage that depends on the input voltage passed on. The relation between the two is shown in figure

