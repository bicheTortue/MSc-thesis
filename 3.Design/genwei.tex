\section{Weights generation}
\label{sec:genwei}

The choice for the weight generation was to use Keras API with the tensorflow framework. However, both tensorflow and pyTorch were tried and were giving similar results, the final choice of using tensorflow was made because it's the most popular among the research group.%INESC ID ???

\subsection{Training the weights}

Generating the weights requires to train a \ac{NN}. This is done in Keras by creating the model, in other words the architecture required to solve the problem. This model contains the description of the \ac{NN}, such as the type of \ac{RNN} and the Dense layers that would come before of after the \ac{RNN}. In Keras, there are only two of the \ac{LSTM} variants (\cref{sec:lstm}) available :

\begin{itemize}
  \item The \ac{NP} \ac{LSTM} : This is most commonly used version and by such one of the two available in Keras.
  \item The \ac{GRU} : This one is present here because it's considered to be different from an \ac{LSTM} \ac{NN} despite their similarities.
\end{itemize}

The other kinds of \ac{LSTM} are not present in the default Keras librairies.

Training can only be done outside of the circuit as this state of the project. However, in order to train the weights as closely as they would have been on a real circuit, the activation functions used for the training are the custom activation functions generated by the dedicated circuit (\cref{sec:af}). In other words, the activation functions used are the ones shown in \cref{fig:afGraph}. This allows to train the weights as they almost (considering the activation functions are recreated using 51 simulated points) as they would have been in the real circuit.

All the weight trainings are done using \ac{MSE} loss function and Adam optimizer \cite{adamOpti}.

\subsection{Exporting the weights}

Once all the parameters (number of hidden states, number of dense layers, etc) have been set. The weights can be exported using the required weight repartition layed out in \cref{sec:netlist}. A description of the architecture is also saved along the weights. This file can now be used as the input for the netlist generator (\cref{sec:netlist}).

The code used for all the weights generations is available at \cite{lstmWei}. %TODO README
