\section{Motivation}
\label{sec:motivation}

Nowadays, it is impossible not to have heard about \acp{AI}, they are everywhere and everybody talks about them. It is common practice to advertise products using \ac{AI} powered tools. \textit{ChatGPT} from \textbf{OpenAI} is a recent example and is getting very popular even among casual computer users. Everyone is using this tool. An older example include home assistants that have been around for about ten years. Those products (such as \textbf{Amazon}'s \textit{Alexa}, \textbf{Google}'s \textit{nest} system and others) are not computing their answers locally, hence creating avoidable internet trafic. It is clear that \ac{AI} is becoming the predominant technology in the modern world and future innovations will depend on it.

\acp{AI} are very power hungry algorithms which limits their use in embedded systems and power efficient devices.
Furthermore, the time an \ac{AI} algorithm takes to compute its output quickly rises, especially on lower end chip such as the ones used in embedded systems. So much so that the most complex ones only run on online and very powerful servers, like the aforementioned \textit{ChatGPT} and home assistants.

There are several options to reduce execution speed and energy consumption such as running the algorithm on a \ac{GPU} rather than on a \ac{CPU}. Using a \ac{FPGA} or \ac{ASIC} are other ways to improve power consumption and execution time.
The latter is the most restricting, as it is name implies, but has the best results.

Using an \ac{ASIC} allows the use of analog computation. Analog computation offers great advantages compared to digital computers as it is much faster while being known to be very power-efficient.

Home assistants could greatly benefit from being able to quickly compute answers without having to connect to an online server. Locally computing answers would drastically improve the usefulness of the device. It could even allow to be used on the go, in a car for example.

Another great use for local \ac{AI} computation would be to use \acp{LLM}, the technology behind \textit{ChatGPT}, for any local use. \acp{LLM} are not the focus of this thesis, but are a long term potential objective of using analog computation for \ac{AI}.

Making analog chips with a very low power consumption also allows to use them in embedded systems such as video surveillance cameras. A small chip could be installed inside the system that could be able to do gait detection \cite{gaitDS,gaitDig,gait}. The video surveillance camera would then be able to know who is showing up on the camera and if it is not a known person send an alert.

Such a chip could also be used for video stabilization \cite{videoStab}. It would allow to directly store stabilized video, and not have to use online servers like described in \cite{videoStab}. Any action camera would benefit greatly from such an improvement since they are mostly used to film scenes with lots of movements.

Another use for \ac{AI} that works great in embedded use is for camera enhanced 3D camera localization \cite{videoReloc}. That is useful especially for \ac{VR} headsets that need to know their location in the room. The embedded chip would allow this computation to be much faster than other methods, and thus give more realistic results.

Some research \cite{celegans}, focuses on reproducing parts of the nervous system of a small organism. This could be applied on larger organisms, or, in the long term, reproduce part of the human brain. Using analog computers, small chips could be used to replace a part of one's brain non functional part.

The focus of this thesis is to create a working simulation of an analog \ac{LSTM} and \ac{GRU} circuit using Cadence's Virtuoso as simulation software. Having those preliminary results would allow to fabricate and test such a chip. Once a working prototype is manufactured, such a circuit could highly improve embedded \ac{AI} use.
